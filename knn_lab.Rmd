---
title: "KNN Lab"
author: "Emma Seiberlich"
date: "4/4/2020"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(class)
library(tidyverse)
```
## Background and Objective
You left your job as a tracking unstructured text as you wanting to expand your skills into predictive models.  Luckily you landed a job in advertising! Unfortunately have a demanding and totally clueless boss. Clueless meaning that he doesn't understand data science, but he knows he wants it to be used to fix all the company's problems and you are just the data scientist to do it! 

Your company, Marketing Enterprises of Halifax or "MEH" is being beat out by the competition and wants a new way to determine the quality of its commercials. Your boss, Mr. Ed Rooney, would like the company's commercials to seem more like actual TV shows. So he wants you to develop a "machine learning thing" using the companyâ€™s internal data to classify when something is a commercial and when it is not. Mr. Rooney believes the company will be able to make more convincing commercials that hold audiences attention if they are more like tv shows and as a result customers will pay more attention, thus buy more of the terrible products "MEH" is supporting (it's a terrible plan, but you have to make a living). 

Given that MEH is producing commercials more or less continuously you know there will be a need to update the model quite frequently, also being a newish data scientist and having a clueless boss you decide to use a accessible approach that you might be able to explain to Mr. Rooney, (given several months of dedicated one on one time), that approach is k-nearest neighbor. 

You'll also need to document your work extensively, because Mr. Rooney doesn't know he's clueless so he will ask lots of "insightful" questions and require lots of detail that he won't understand, so you'll need to have an easy to use reference document. Before you get started you hearken back to the excellent education you received at UVA and using this knowledge outline roughly 15 steps that need to be completed to build this algo for MEH and Ed, they are documented below...good luck. As always, the most important part is translating your work to actionable insights, so please make sure to be verbose in the explanation required for step 15. Think about this questions carefully, what are you really delivering to Mr. Rooney? 

As with the clustering lab, please be prepared to present a five minute overview of your findings. 
 
## Load Data  & Labels
```{r}
#1
#Load in the data, both the commercial dataset and the labels. You'll need to the place the labels on the columns. The dataset "tv_commercialsets-CNN_Cleaned.csv",  is data collected about the features of commercials on CNN. We can try to predict what segments of video are commercials based on their audio and video components. More information on the datasets can be found data.world:
# https://data.world/kramea/tv-commercial-detection/workspace/file?filename=tv_commercial_datasets%2FBBC_Cleaned.csv

#You can use the function colnames() to apply the labels (hint: you might need to reshape the labels to make this work)
CNN<- read.csv("tv_commercial_datasets_CNN_Cleaned.csv")
labels<- read.csv("cnn_commmercial_label.csv", header=FALSE)
colnames(CNN)<-t(labels) # set the column names as the labels list
```
# Finding our split and base rate
```{r,echo=FALSE}
#2. Determine the split between commercial and non-commercial then calculate the base rate, assume 1 is the commercial label and -1 is the non-commercial label 
print(table(CNN$`label `))

print(table(CNN$`label`)[2] / sum(table(CNN$`label `)))

```
There are 8134 non-commercials, and 14411 commercials.
As shown from the 'base rate', we have about a 63.9% chance of correctly choosing whether or not something is a commercial at random. 

```{r, echo=FALSE}
#3. Since there are columns that contain different metrics for the same variable (i.e. any column that ends in 'mn' is the mean of that variable, while any column that ends in 'var' is the variance of that variable), we don't need to keep both, drop all the columns that include var
CNNmean<- CNN[,c(1,2,4,6,8,10,12,14,16,18,20)] #create new df

```
## Correlation matrix
```{r}
#4.  Before we run kNN, sometimes it's good to check to make sure that our variables are not highly correlated. Use the cor() function on 'your_dataframe', label it 'commercial_correlations', and view the data, because remember kNN doesn't work well in high dimensions. 

commercial_correlations<- cor(CNNmean)
commercial_correlations
```
## Remove highly correlated variables
From taking a look at the correlation matrix, we see that the following pairs are correlated above an absolute value of .7:
motion_distr with frame_diff_dist
motion_distr with motion_dist

short_time_energy with spectral_flux

spectral_centroid with spectral_roll_off


So, we will make sure to remove motion_distr since it is highly correlated with frame_diff_dist_mn and motion_dist_mn. I am choosing to leave in the variables that are highly correlated with only 1 other variable, so we don't have to remove 4 additional variables of the 10 that remain.
```{r}
#5. Determine which variables to remove, high correlations start around .7 or below -.7 I would especially remove variables that appear to be correlated with more than one variable. List your rationale here:
CNNpart5<- CNNmean[,-2] #take out motion_distr_mn
head(CNNpart5)
```

## Generating train and test sets
```{r}
#6. Use the index to generate a train and test sets, then check the row counts to be safe.
set.seed(2021)
CNNtrainingrows <- sample(1:nrow(CNNpart5),# length of cut down datset
                              round(0.8 * nrow(CNNpart5), 0),  #<- multiply the number of rows by 0.8 and round the decimals
                              replace = FALSE)#<- don't replace the numbers

#confirm that length is right around 80%:
length(CNNtrainingrows) / nrow(CNNpart5)


CNNtraining<- CNNpart5[CNNtrainingrows,]
CNNtesting<- CNNpart5[-CNNtrainingrows,]

# Check the number of rows in each set.
nrow(CNNtraining) #the 80% training
nrow(CNNtesting) #the 20 % testing

print(nrow(CNNtraining)+
        nrow(CNNtesting))
#sum is original 22545 rows 
```

## Train the classifier
```{r}

#7 Train the classifier using k = 3, remember to set.seed so you can repeat the output and to use the labels as a vector for the class (not a index of the dataframe)
set.seed(2021)
CNN_3NN <-  knn(train = CNNtraining[, c("shot_length",
                                       "frame_diff_dist_mn",
                                       "short_time_energy_mn",
                                       "zcr_mn",
                                       "spectral_centroid_mn",
                                       "spectral_roll_off_mn",
                                       "spectral_flux_mn",
                                       "fundamental_freq_mn",
                                       "motion_dist_mn")],#<- training set cases
               test = CNNtesting[, c("shot_length",
                                       "frame_diff_dist_mn",
                                       "short_time_energy_mn",
                                       "zcr_mn",
                                       "spectral_centroid_mn",
                                       "spectral_roll_off_mn",
                                       "spectral_flux_mn",
                                       "fundamental_freq_mn",
                                       "motion_dist_mn")],    #<- test set cases
               cl = CNNtraining$`label `,#<- category for true classification
               k = 3,#<- number of neighbors considered
               use.all = TRUE,
               prob = TRUE)

str(CNN_3NN)
length(CNN_3NN) #same length as testing set
table(CNN_3NN)

```

## Confusion matrix with k=3
```{r}
#8 Create a initial confusion matrix using the table function and pass it to a object. (xx <- your confusion matrix)

confusion1<- table(CNN_3NN,#what we are predicting 
               CNNtesting$`label `)
confusion1 #initial confusion matrix
```

## Accuracy and Sensitivity rates for k=3
```{r}
#9  Run the confusion matrix function and comment on the model output
confusion1[row(confusion1) == col(confusion1)] #shows 899, 2394 correct predictions
CNNaccuracy <-  sum(confusion1[row(confusion1) == col(confusion1)]) / sum(confusion1) #accuracy rate
CNNaccuracy

CNNsensitivity<- confusion1[2,2]/(confusion1[2,2]+confusion1[1,2])
CNNsensitivity
library(caret)

```
From this analysis, we can conclude that our kNN with k=3 model is about 73 percent accurate. Our calculated sensitivity rate , or the true positive rate, is about 84%.  


```{r, echo=FALSE}
#10 Run the "chooseK" function to find the perfect K, while using sapply() function on chooseK() to test k from 1 to 21 (only selecting the odd numbers), and set the train_set argument to 'commercial_train', val_set to 'commercial_test', train_class to the "label"   column of 'commercial_train', and val_class to the "label" column of 'commercial_test'. Label this  "knn_diff_k_com"

chooseK = function(k, train_set, val_set, train_class, val_class){
  
  # Build knn with k neighbors considered.
  set.seed(1)
  class_knn = knn(train = train_set,    #<- training set cases
                  test = val_set,       #<- test set cases
                  cl = train_class,     #<- category for classification
                  k = k,                #<- number of neighbors considered
                  use.all = TRUE)       #<- control ties between class assignments#   If true, all distances equal to the kth largest are included
  conf_mat = table(class_knn, val_class)
  
  # Calculate the accuracy#could change this to Sensitivity 
  accu = sum(conf_mat[row(conf_mat) == col(conf_mat)]) / sum(conf_mat)                         
  cbind(k = k, accuracy = accu)
}

CNNknn_different_k = sapply(seq(1, 21, by = 2),  #<- set k to be odd number from 1 to 21
                         function(x) chooseK(x, 
                                             train_set = CNNtraining[, c("shot_length",
                                       "frame_diff_dist_mn",
                                       "short_time_energy_mn",
                                       "zcr_mn",
                                       "spectral_centroid_mn",
                                       "spectral_roll_off_mn",
                                       "spectral_flux_mn",
                                       "fundamental_freq_mn",
                                       "motion_dist_mn")],
                                             val_set = CNNtesting[, c("shot_length",
                                       "frame_diff_dist_mn",
                                       "short_time_energy_mn",
                                       "zcr_mn",
                                       "spectral_centroid_mn",
                                       "spectral_roll_off_mn",
                                       "spectral_flux_mn",
                                       "fundamental_freq_mn",
                                       "motion_dist_mn")],
                                             train_class = CNNtraining$`label `,
                                             val_class = CNNtesting$`label `))


```

## Step 11: K vs. Accuracy DF
```{r, echo=FALSE}
#11 Create a dataframe so we can visualize the difference in accuracy based on K, convert the matrix to a dataframe

KvsAccuracy<-  tibble(k = CNNknn_different_k[1,],
                             accuracy = CNNknn_different_k[2,])
df1=as.data.frame(KvsAccuracy)
df1
```

## Ggplot-- K vs. Accuracy
```{r, echo=FALSE}
#12 Use ggplot to show the output and comment on the k to select.
ggplot(df1,
       aes(x = k, y = accuracy)) +
  geom_line(color = "orange", size = 1.5) +
  geom_point(size = 3)
```
From the chart shown, it looks like a k of 7 is an ideal choice to move forward. Any k > 7 has only incremental increases in accuracy, so it's best to keep the model as simple as we can by sticking with a k of 7.


```{r}
#13 Rerun the model  with the k you selected, assuming it's different. 
set.seed(2021)
CNN_7NN <-  knn(train = CNNtraining[, c("shot_length",
                                       "frame_diff_dist_mn",
                                       "short_time_energy_mn",
                                       "zcr_mn",
                                       "spectral_centroid_mn",
                                       "spectral_roll_off_mn",
                                       "spectral_flux_mn",
                                       "fundamental_freq_mn",
                                       "motion_dist_mn")],#<- training set cases
               test = CNNtesting[, c("shot_length",
                                       "frame_diff_dist_mn",
                                       "short_time_energy_mn",
                                       "zcr_mn",
                                       "spectral_centroid_mn",
                                       "spectral_roll_off_mn",
                                       "spectral_flux_mn",
                                       "fundamental_freq_mn",
                                       "motion_dist_mn")],    #<- test set cases
               cl = CNNtraining$`label `,#<- category for true classification
               k = 7,#<- number of neighbors considered
               use.all = TRUE,
               prob = TRUE)


```
## K of 7 Confusion matrix
```{r, echo=FALSE}
#14 Use the confusion matrix function to measure the quality of the new model.
confusion2<- table(CNN_7NN,
               CNNtesting$`label `)
confusion2

confusion2[row(confusion2) == col(confusion2)] #shows 864, 2539 correct predictions
CNN7accuracy <-  sum(confusion2[row(confusion2) == col(confusion2)]) / sum(confusion2) #accuracy rate
CNN7accuracy

CNN7sensitivity<- confusion2[2,2]/(confusion2[2,2]+confusion2[1,2])
CNN7sensitivity
```

```{r}
#15 Summarize the differences in language Mr. Rooney may actually understand. Include a discussion on which approach k=3 or k="optimal" is the better method moving forward for "MEH". Most importantly draft comments about the overall approach and model quality as it relates to addressing the problem proposed by Ed. 

```
After evaluating k=3 versus k=7 (the 'optimal' k I chose), I found that 7 increased accuracy by about 2% and sensitivity by a little more than 5% when compared with using a k of 3. I would suggest using a k nearest-neighbors model with a k of 7 to move forward. Accuracy is a measure of how well the model predicts correctly, regardless of whether or not it predicts if something is or is not a commercial.\
Sensitivity is a measure of the rate of true positives that the model correctly identifies. In our case, sensitivity would mean "how many media pieces that are indeed commercials did the model correctly predict?" With a pretty high sensitivity rate of 89.1, I think this model does a fine job of correctly predicting that a commercial is indeed a commercial.
